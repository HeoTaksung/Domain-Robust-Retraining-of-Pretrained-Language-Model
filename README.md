# Domain-Robust-Retraining-of-Pretrained-Language-Model

  * 한국어에 대한 많은 PLM(Pretrained Language Model)들이 있지만, 대부분 문어체에 대한 PLM이 존재합니다. 여기서는 한국어 대화(구어체) 데이터의 예측을 위한 재학습된 PLM을 소개합니다.
  * 이 모델은 klue/roberta-base를 기본 모델로 삼고 구어체 데이터셋을 추가적으로 Retraining을 시킨 것으로, 우리는 이를 dq-roberta로 정의합니다.

